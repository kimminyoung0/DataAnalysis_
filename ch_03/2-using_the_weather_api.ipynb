{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting temperature data from an API\n",
    "\n",
    "## About the data\n",
    "In this notebook, we will be collecting daily temperature data from the [National Centers for Environmental Information (NCEI) API](https://www.ncdc.noaa.gov/cdo-web/webservices/v2). We will use the Global Historical Climatology Network - Daily (GHCND) dataset; see the documentation [here](https://www1.ncdc.noaa.gov/pub/data/cdo/documentation/GHCND_documentation.pdf).\n",
    "\n",
    "## Using the NCEI API\n",
    " [here](https://www.ncdc.noaa.gov/cdo-web/token) 에서 토큰 요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def make_request(endpoint, payload=None):\n",
    "    \"\"\"\n",
    "    헤더와 선택적 페이로드를 전달하는 기상 API의 특정 종단점에 요청한다.\n",
    "    \n",
    "    매개변수(Parameters):\n",
    "        -종단점(endpoint) :GET 요청(request)을 하려는 API의 종단점\n",
    "        -페이로드(payload): 요청과 함께 전달할 데이터의 딕셔너리\n",
    "        \n",
    "    반환값(Returns):\n",
    "        응답(response) 객체\n",
    "    \"\"\"\n",
    "    return requests.get(\n",
    "        f'https://www.ncdc.noaa.gov/cdo-web/api/v2/{endpoint}',\n",
    "        headers={\n",
    "            'token': 'rmGGNDuTrUhcSoddJhzlmXctMUBcEqzK'\n",
    "        },\n",
    "        params=payload\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: API는 초당 5개의 요청과 1일 1만건의 요청으로 제한된다..**\n",
    "\n",
    "제한을 초과하면 상태코드가 클라이언트 에러 표시(400번대)\n",
    "\n",
    "-404요청 받은 자원을 찾을 수 없다.\n",
    "\n",
    "-400서버가 요청을 이해할 수 앖가니 요청 처리를 거부했다는 것\n",
    "\n",
    "서버의 에러상태 표시(500번대)\n",
    "\n",
    "## See which datasets are available\n",
    "다음과 같은 코드로 2018년 10월 1일부터 오늘 날짜까지의 범위ㅏ의 데이터셋을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = make_request('datasets', {'startdate': '2018-10-01'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요청이 성공했는지 확인하려면 status_code 속성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ok` 속성으로도 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get the keys of the result\n",
    "응답을 받으면 json()메서드를 이용해 페이로드를 얻을 수 있다.\n",
    "\n",
    "그 후, 딕셔너리 메서드를 사용해보고 싶은 부분을 선택할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['metadata', 'results'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = response.json()\n",
    "payload.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**metadata**는 결과데이터에 관한 정보\n",
    "\n",
    "**results**는 실제 결과 데이터가 들어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resultset': {'offset': 1, 'count': 11, 'limit': 25}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload['metadata']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> 결과 데이터에 **11개의 행**이 있는 걸 알 수 있다. **(count: 11)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out what data is in the result \n",
    "`results` 키를 확인해서 어떤 필드가 있는지 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['uid', 'mindate', 'maxdate', 'name', 'datacoverage', 'id'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload['results'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the result\n",
    "모든 필드가 필요한 것이 아니므로 리스트 컴프리헨션을 적용해 \n",
    "\n",
    "**`id`와 `name` 만 볼 수 있도록** 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GHCND', 'Daily Summaries'),\n",
       " ('GSOM', 'Global Summary of the Month'),\n",
       " ('GSOY', 'Global Summary of the Year'),\n",
       " ('NEXRAD2', 'Weather Radar (Level II)'),\n",
       " ('NEXRAD3', 'Weather Radar (Level III)'),\n",
       " ('NORMAL_ANN', 'Normals Annual/Seasonal'),\n",
       " ('NORMAL_DLY', 'Normals Daily'),\n",
       " ('NORMAL_HLY', 'Normals Hourly'),\n",
       " ('NORMAL_MLY', 'Normals Monthly'),\n",
       " ('PRECIP_15', 'Precipitation 15 Minute'),\n",
       " ('PRECIP_HLY', 'Precipitation Hourly')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(data['id'], data['name']) for data in payload['results']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out which data category we want\n",
    "The `GHCND` data containing daily summaries is what we want. Now we need to make another request to figure out which data categories we want to collect. This is the `datacategories` endpoint. We have to pass the `datasetid` for `GHCND` as the payload so the API knows which dataset we are asking about:\n",
    "\n",
    "결과의 첫번째 항목이 우리가 필요한 데이터이다. 이제 datasetid에 대한 값 GHCND을 얻었으므로 기온 데이터 요청에 필요한 datacategoryid에 대한 값을 식별해야 한다. 이를 위해 datacategories 종단점을 사용한다. \n",
    "\n",
    "여기서는 JSON 페이로드가 그리 크지 않으므로 JSON페이로드를 인쇄할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data category id\n",
    "response = make_request(\n",
    "    'datacategories', payload={'datasetid': 'GHCND'}\n",
    ")\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know the API gives us a `metadata` and a `results` key in each response, we can see what is in the `results` portion of the JSON payload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Evaporation', 'id': 'EVAP'},\n",
       " {'name': 'Land', 'id': 'LAND'},\n",
       " {'name': 'Precipitation', 'id': 'PRCP'},\n",
       " {'name': 'Sky cover & clouds', 'id': 'SKY'},\n",
       " {'name': 'Sunshine', 'id': 'SUN'},\n",
       " {'name': 'Air Temperature', 'id': 'TEMP'},\n",
       " {'name': 'Water', 'id': 'WATER'},\n",
       " {'name': 'Wind', 'id': 'WIND'},\n",
       " {'name': 'Weather Type', 'id': 'WXTYPE'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab the data type ID for the temperature category\n",
    "We will be working with temperatures, so we want the `TEMP` data category. Now, we need to find the `datatypes` to collect. For this, we use the `datatypes` endpoint and provide the `datacategoryid` which was `TEMP`. We also specify a limit for the number of `datatypes` to return with the payload. If there are more than this we can make another request later, but for now, we just want to pick a few out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data type id\n",
    "response = make_request(\n",
    "    'datatypes',\n",
    "    payload={\n",
    "        'datacategoryid': 'TEMP', \n",
    "        'limit': 100\n",
    "    }\n",
    ")\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can grab the `id` and `name` fields for each of the entries in the `results` portion of the data. The fields we are interested in are at the bottom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MNTM', 'Monthly mean temperature'),\n",
       " ('TAVG', 'Average Temperature.'),\n",
       " ('TMAX', 'Maximum temperature'),\n",
       " ('TMIN', 'Minimum temperature'),\n",
       " ('TOBS', 'Temperature at the time of observation')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(datatype['id'], datatype['name']) for datatype in response.json()['results']][-5:] # look at the last 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine which location category we want\n",
    "Now that we know which `datatypes` we will be collecting, we need to find the location to use. First, we need to figure out the location category. This is obtained from the `locationcategories` endpoint by passing the `datasetid`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get location category id \n",
    "response = make_request(\n",
    "    'locationcategories', \n",
    "    payload={'datasetid': 'GHCND'}\n",
    ")\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `pprint` to print dictionaries in an easier-to-read format. After doing so, we can see there are 12 different location categories, but we are only interested in `CITY`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'resultset': {'count': 12, 'limit': 25, 'offset': 1}},\n",
      " 'results': [{'id': 'CITY', 'name': 'City'},\n",
      "             {'id': 'CLIM_DIV', 'name': 'Climate Division'},\n",
      "             {'id': 'CLIM_REG', 'name': 'Climate Region'},\n",
      "             {'id': 'CNTRY', 'name': 'Country'},\n",
      "             {'id': 'CNTY', 'name': 'County'},\n",
      "             {'id': 'HYD_ACC', 'name': 'Hydrologic Accounting Unit'},\n",
      "             {'id': 'HYD_CAT', 'name': 'Hydrologic Cataloging Unit'},\n",
      "             {'id': 'HYD_REG', 'name': 'Hydrologic Region'},\n",
      "             {'id': 'HYD_SUB', 'name': 'Hydrologic Subregion'},\n",
      "             {'id': 'ST', 'name': 'State'},\n",
      "             {'id': 'US_TERR', 'name': 'US Territory'},\n",
      "             {'id': 'ZIP', 'name': 'Zip Code'}]}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get NYC Location ID\n",
    "In order to find the location ID for New York, we need to search through all the cities available. Since we can ask the API to return the cities sorted, we can use binary search to find New York quickly without having to make many requests or request lots of data at once. The following function makes the first request to see how big the list is and looks at the first value. From there it decides if it needs to move towards the beginning or end of the list by comparing the item we are looking for to others alphabetically. Each time it makes a request it can rule out half of the remaining data to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item(name, what, endpoint, start=1, end=None):\n",
    "    \"\"\"\n",
    "    Grab the JSON payload for a given field by name using binary search.\n",
    "\n",
    "    Parameters:\n",
    "        - name: The item to look for.\n",
    "        - what: Dictionary specifying what the item in `name` is.\n",
    "        - endpoint: Where to look for the item.\n",
    "        - start: The position to start at. We don't need to touch this, but the\n",
    "                 function will manipulate this with recursion.\n",
    "        - end: The last position of the items. Used to find the midpoint, but\n",
    "               like `start` this is not something we need to worry about.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of the information for the item if found otherwise \n",
    "        an empty dictionary.\n",
    "    \"\"\"\n",
    "    # find the midpoint which we use to cut the data in half each time\n",
    "    mid = (start + (end or 1)) // 2\n",
    "    \n",
    "    # lowercase the name so this is not case-sensitive\n",
    "    name = name.lower()\n",
    "    \n",
    "    # define the payload we will send with each request\n",
    "    payload = {\n",
    "        'datasetid': 'GHCND',\n",
    "        'sortfield': 'name',\n",
    "        'offset': mid, # we will change the offset each time\n",
    "        'limit': 1 # we only want one value back\n",
    "    }\n",
    "    \n",
    "    # make our request adding any additional filter parameters from `what`\n",
    "    response = make_request(endpoint, {**payload, **what})\n",
    "    \n",
    "    if response.ok:\n",
    "        payload = response.json()\n",
    "\n",
    "        # if response is ok, grab the end index from the response metadata the first time through\n",
    "        end = end or payload['metadata']['resultset']['count']\n",
    "        \n",
    "        # grab the lowercase version of the current name\n",
    "        current_name = payload['results'][0]['name'].lower()\n",
    "        \n",
    "        # if what we are searching for is in the current name, we have found our item\n",
    "        if name in current_name:\n",
    "            return payload['results'][0] # return the found item\n",
    "        else:\n",
    "            if start >= end: \n",
    "                # if our start index is greater than or equal to our end, we couldn't find it\n",
    "                return {}\n",
    "            elif name < current_name:\n",
    "                # our name comes before the current name in the alphabet, so we search further to the left\n",
    "                return get_item(name, what, endpoint, start, mid - 1)\n",
    "            elif name > current_name:\n",
    "                # our name comes after the current name in the alphabet, so we search further to the right\n",
    "                return get_item(name, what, endpoint, mid + 1, end)    \n",
    "    else:\n",
    "        # response wasn't ok, use code to determine why\n",
    "        print(f'Response not OK, status: {response.status_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use binary search to find New York, we find it in just 8 requests despite it being close to the middle of 1,983 entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mindate': '1869-01-01',\n",
       " 'maxdate': '2021-01-14',\n",
       " 'name': 'New York, NY US',\n",
       " 'datacoverage': 1,\n",
       " 'id': 'CITY:US360019'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get NYC id \n",
    "nyc = get_item('New York', {'locationcategoryid': 'CITY'}, 'locations')\n",
    "nyc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the station ID for Central Park\n",
    "The most granular data is found at the station level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elevation': 42.7,\n",
       " 'mindate': '1869-01-01',\n",
       " 'maxdate': '2021-01-13',\n",
       " 'latitude': 40.77898,\n",
       " 'name': 'NY CITY CENTRAL PARK, NY US',\n",
       " 'datacoverage': 1,\n",
       " 'id': 'GHCND:USW00094728',\n",
       " 'elevationUnit': 'METERS',\n",
       " 'longitude': -73.96925}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "central_park = get_item('NY City Central Park', {'locationid': nyc['id']}, 'stations')\n",
    "central_park"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request the temperature data\n",
    "Finally, we have everything we need to make our request for the New York temperature data. For this, we use the `data` endpoint and provide all the parameters we picked up throughout our exploration of the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get NYC daily summaries data \n",
    "response = make_request(\n",
    "    'data', \n",
    "    {\n",
    "        'datasetid': 'GHCND',\n",
    "        'stationid': central_park['id'],\n",
    "        'locationid': nyc['id'],\n",
    "        'startdate': '2018-10-01',\n",
    "        'enddate': '2018-10-31',\n",
    "        'datatypeid': ['TAVG', 'TMAX', 'TMIN'], # average, max, and min temperature\n",
    "        'units': 'metric',\n",
    "        'limit': 1000\n",
    "    }\n",
    ")\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DataFrame\n",
    "The Central Park station only has the daily minimum and maximum temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>datatype</th>\n",
       "      <th>station</th>\n",
       "      <th>attributes</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-01T00:00:00</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>GHCND:USW00094728</td>\n",
       "      <td>,,W,2400</td>\n",
       "      <td>24.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-01T00:00:00</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>GHCND:USW00094728</td>\n",
       "      <td>,,W,2400</td>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-02T00:00:00</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>GHCND:USW00094728</td>\n",
       "      <td>,,W,2400</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-10-02T00:00:00</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>GHCND:USW00094728</td>\n",
       "      <td>,,W,2400</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-03T00:00:00</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>GHCND:USW00094728</td>\n",
       "      <td>,,W,2400</td>\n",
       "      <td>23.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date datatype            station attributes  value\n",
       "0  2018-10-01T00:00:00     TMAX  GHCND:USW00094728   ,,W,2400   24.4\n",
       "1  2018-10-01T00:00:00     TMIN  GHCND:USW00094728   ,,W,2400   17.2\n",
       "2  2018-10-02T00:00:00     TMAX  GHCND:USW00094728   ,,W,2400   25.0\n",
       "3  2018-10-02T00:00:00     TMIN  GHCND:USW00094728   ,,W,2400   18.3\n",
       "4  2018-10-03T00:00:00     TMAX  GHCND:USW00094728   ,,W,2400   23.3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(response.json()['results'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't get `TAVG` because the station doesn't measure that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TMAX', 'TMIN'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.datatype.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite showing up in the data as measuring it... Real-world data is dirty!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n"
     ]
    }
   ],
   "source": [
    "if get_item(\n",
    "    'NY City Central Park', {'locationid': nyc['id'], 'datatypeid': 'TAVG'}, 'stations'\n",
    "):\n",
    "    print('Found!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a different station\n",
    "Let's use LaGuardia airport instead. It contains `TAVG` (average daily temperature):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elevation': 3.4,\n",
       " 'mindate': '1939-10-07',\n",
       " 'maxdate': '2021-01-14',\n",
       " 'latitude': 40.77944,\n",
       " 'name': 'LAGUARDIA AIRPORT, NY US',\n",
       " 'datacoverage': 1,\n",
       " 'id': 'GHCND:USW00014732',\n",
       " 'elevationUnit': 'METERS',\n",
       " 'longitude': -73.88035}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laguardia = get_item(\n",
    "    'LaGuardia', {'locationid': nyc['id']}, 'stations'\n",
    ")\n",
    "laguardia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make our request using the LaGuardia airport station this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get NYC daily summaries data \n",
    "response = make_request(\n",
    "    'data', \n",
    "    {\n",
    "        'datasetid': 'GHCND',\n",
    "        'stationid': laguardia['id'],\n",
    "        'locationid': nyc['id'],\n",
    "        'startdate': '2018-10-01',\n",
    "        'enddate': '2018-10-31',\n",
    "        'datatypeid': ['TAVG', 'TMAX', 'TMIN'], # temperature at time of observation, min, and max\n",
    "        'units': 'metric',\n",
    "        'limit': 1000\n",
    "    }\n",
    ")\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The request was successful, so let's make a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>datatype</th>\n",
       "      <th>station</th>\n",
       "      <th>attributes</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-01T00:00:00</td>\n",
       "      <td>TAVG</td>\n",
       "      <td>GHCND:USW00014732</td>\n",
       "      <td>H,,S,</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-01T00:00:00</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>GHCND:USW00014732</td>\n",
       "      <td>,,W,2400</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-01T00:00:00</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>GHCND:USW00014732</td>\n",
       "      <td>,,W,2400</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-10-02T00:00:00</td>\n",
       "      <td>TAVG</td>\n",
       "      <td>GHCND:USW00014732</td>\n",
       "      <td>H,,S,</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-02T00:00:00</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>GHCND:USW00014732</td>\n",
       "      <td>,,W,2400</td>\n",
       "      <td>26.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date datatype            station attributes  value\n",
       "0  2018-10-01T00:00:00     TAVG  GHCND:USW00014732      H,,S,   21.2\n",
       "1  2018-10-01T00:00:00     TMAX  GHCND:USW00014732   ,,W,2400   25.6\n",
       "2  2018-10-01T00:00:00     TMIN  GHCND:USW00014732   ,,W,2400   18.3\n",
       "3  2018-10-02T00:00:00     TAVG  GHCND:USW00014732      H,,S,   22.7\n",
       "4  2018-10-02T00:00:00     TMAX  GHCND:USW00014732   ,,W,2400   26.1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(response.json()['results'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should check that we got what we wanted: 31 entries for TAVG, TMAX, and TMIN (1 per day):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TMAX    31\n",
       "TMIN    31\n",
       "TAVG    31\n",
       "Name: datatype, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.datatype.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the data to a CSV file for use in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/nyc_temperatures.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<div>\n",
    "    <a href=\"./1-wide_vs_long.ipynb\">\n",
    "        <button>&#8592; Previous Notebook</button>\n",
    "    </a>\n",
    "    <a href=\"./3-cleaning_data.ipynb\">\n",
    "        <button style=\"float: right;\">Next Notebook &#8594;</button>\n",
    "    </a>\n",
    "</div>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
